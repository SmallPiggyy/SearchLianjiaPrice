from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException
import time
import random
import csv
from urllib.parse import quote


# -------------------------- å¤„ç†æéªŒéªŒè¯çš„æ ¸å¿ƒå‡½æ•° --------------------------
def handle_geetest():
    """å¤„ç†æéªŒç‚¹é€‰éªŒè¯ç ï¼šç‚¹å‡»åˆå§‹æŒ‰é’® â†’ è¯†åˆ«æ±‰å­—é¡ºåº â†’ ä¾æ¬¡ç‚¹å‡» â†’ ç¡®è®¤"""
    try:
        # 1. ç­‰å¾…å¹¶ç‚¹å‡»åˆå§‹éªŒè¯æŒ‰é’®ï¼ˆid="captcha"å†…çš„ç‚¹å‡»åŒºåŸŸï¼‰
        captcha_btn = WebDriverWait(driver, 10).until(
            EC.element_to_be_clickable((By.CSS_SELECTOR, "#captcha .geetest_btn_click"))
        )
        captcha_btn.click()
        time.sleep(1)

        # 2. ç­‰å¾…éªŒè¯å¼¹çª—å‡ºç°ï¼ˆ.geetest_window æ˜¯éªŒè¯ç çª—å£ï¼‰
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, ".geetest_window"))
        )

        # 3. è·å–éœ€è¦ç‚¹å‡»çš„æ±‰å­—é¡ºåºï¼ˆé€šå¸¸åœ¨å¼¹çª—é¡¶éƒ¨çš„æç¤ºæ–‡å­—ä¸­ï¼Œå¦‚â€œè¯·ä¾æ¬¡ç‚¹å‡»ï¼šå›½ã€å®¶ã€äººâ€ï¼‰
        # æ³¨æ„ï¼šå®é™…æ–‡å­—ä½ç½®å¯èƒ½éšç‰ˆæœ¬å˜åŒ–ï¼Œéœ€é€šè¿‡å¼€å‘è€…å·¥å…·ç¡®è®¤
        try:
            tip_text = driver.find_element(By.CSS_SELECTOR, ".geetest_tip_content").text
            # æå–æ±‰å­—ï¼ˆå‡è®¾æ ¼å¼ä¸ºâ€œè¯·ä¾æ¬¡ç‚¹å‡»ï¼šXã€Yã€Zâ€ï¼‰
            target_chars = [c.strip() for c in tip_text.split("ï¼š")[-1].split("ã€")]
            print(f"éœ€è¦ç‚¹å‡»çš„æ±‰å­—é¡ºåºï¼š{target_chars}")
        except:
            print("æ— æ³•è¯†åˆ«æ±‰å­—é¡ºåºï¼Œå¯èƒ½éœ€è¦æ‰‹åŠ¨å¹²é¢„")
            target_chars = []

        # 4. å®šä½éªŒè¯ç å›¾ç‰‡åŒºåŸŸï¼ˆ.geetest_bg æ˜¯å›¾ç‰‡å®¹å™¨ï¼‰
        bg_element = driver.find_element(By.CSS_SELECTOR, ".geetest_bg")
        # è·å–å›¾ç‰‡åŒºåŸŸçš„åæ ‡å’Œå°ºå¯¸ï¼ˆç”¨äºè®¡ç®—ç‚¹å‡»ä½ç½®ï¼‰
        bg_location = bg_element.location
        bg_size = bg_element.size

        # 5. éå†ç›®æ ‡æ±‰å­—ï¼Œä¾æ¬¡ç‚¹å‡»ï¼ˆæ ¸å¿ƒï¼šéœ€è¦è¯†åˆ«å›¾ç‰‡ä¸­æ¯ä¸ªæ±‰å­—çš„ä½ç½®ï¼Œè¿™é‡Œç®€åŒ–ä¸ºæ¨¡æ‹Ÿç‚¹å‡»ï¼‰
        # æ³¨æ„ï¼šå®é™…éœ€ç»“åˆå›¾ç‰‡è¯†åˆ«ï¼ˆå¦‚OCRï¼‰å®šä½æ±‰å­—ä½ç½®ï¼Œæ­¤å¤„ä»…ä¸ºæµç¨‹ç¤ºä¾‹
        if target_chars:
            for char in target_chars:
                # æ¨¡æ‹Ÿç‚¹å‡»å›¾ç‰‡åŒºåŸŸå†…çš„éšæœºä½ç½®ï¼ˆå®é™…éœ€æ›¿æ¢ä¸ºOCRè¯†åˆ«çš„åæ ‡ï¼‰
                x = bg_location['x'] + random.randint(50, bg_size['width'] - 50)
                y = bg_location['y'] + random.randint(50, bg_size['height'] - 50)
                driver.execute_script(f"arguments[0].click();", bg_element)  # ç‚¹å‡»å›¾ç‰‡
                time.sleep(0.5)

        # 6. ç‚¹å‡»ç¡®è®¤æŒ‰é’®ï¼ˆ.geetest_submit æ˜¯ç¡®è®¤æŒ‰é’®ï¼‰
        submit_btn = driver.find_element(By.CSS_SELECTOR, ".geetest_submit")
        submit_btn.click()
        time.sleep(2)  # ç­‰å¾…éªŒè¯ç»“æœ

        # 7. éªŒè¯æ˜¯å¦æˆåŠŸï¼ˆè‹¥éªŒè¯çª—å£æ¶ˆå¤±ï¼Œåˆ™è§†ä¸ºæˆåŠŸï¼‰
        if not driver.find_elements(By.CSS_SELECTOR, ".geetest_window"):
            print("âœ…  éªŒè¯ç éªŒè¯æˆåŠŸ")
            return True
        else:
            print("âŒ  éªŒè¯ç éªŒè¯å¤±è´¥ï¼Œé‡è¯•...")
            return False

    except TimeoutException:
        print("â°  éªŒè¯ç å…ƒç´ åŠ è½½è¶…æ—¶")
        return False
    except Exception as e:
        print(f"âŒ  éªŒè¯å¤„ç†é”™è¯¯ï¼š{str(e)}")
        return False

# -------------------------- çˆ¬å–å‡½æ•° --------------------------
def crawl_page(page):
    if page in BLOCKED_PAGES:
        print(f"âš ï¸  è·³è¿‡å·²çŸ¥éªŒè¯é¡µï¼š{page}")
        return

    # æ„é€ URL
    encoded_region = quote(TARGET_REGION, encoding='utf-8')
    url = f'https://sh.lianjia.com/zufang/pg{page}rs{encoded_region}/#contentList'
    driver.get(url)
    time.sleep(random.uniform(1, 2))  # éšæœºå»¶è¿Ÿ

    # æ£€æŸ¥æ˜¯å¦è§¦å‘éªŒè¯ç 
    try:
        # è‹¥å­˜åœ¨id="captcha"å…ƒç´ ï¼Œè¯´æ˜è§¦å‘éªŒè¯
        if driver.find_elements(By.ID, "captcha"):
            print(f"âš ï¸  é¡µç {page}è§¦å‘éªŒè¯ç ï¼Œå¼€å§‹å¤„ç†...")
            # æœ€å¤šå°è¯•3æ¬¡éªŒè¯
            for _ in range(3):
                if handle_geetest():
                    break
                time.sleep(2)
            else:
                print(f"âŒ  é¡µç {page}éªŒè¯å¤±è´¥ï¼Œæ ‡è®°ä¸º blocked")
                BLOCKED_PAGES.add(page)
                return
    except:
        pass

    # éªŒè¯é€šè¿‡åï¼Œè§£æé¡µé¢æ•°æ®
    try:
        # ç­‰å¾…æˆ¿æºåˆ—è¡¨åŠ è½½
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "div.content__list--item[data-el='listItem']"))
        )
        house_list = driver.find_elements(By.CSS_SELECTOR, "div.content__list--item[data-el='listItem']")
        print(f"âœ…  é¡µç {page}æ‰¾åˆ°{len(house_list)}æ¡æˆ¿æº")

        for house in house_list:
            # æå–æ•°æ®ï¼ˆä¸ä¹‹å‰é€»è¾‘ä¸€è‡´ï¼Œæ”¹ç”¨Seleniumçš„å…ƒç´ å®šä½ï¼‰
            title = house.find_element(By.CSS_SELECTOR, "p.content__list--item--title a").text.strip()
            price = house.find_element(By.CSS_SELECTOR, "span.content__list--item-price em").text + " å…ƒ/æœˆ"
            area_info = [a.text for a in house.find_elements(By.CSS_SELECTOR, "p.content__list--item--des a")]
            area = '-'.join(area_info) if area_info else 'æ— åŒºåŸŸä¿¡æ¯'
            link = house.find_element(By.CSS_SELECTOR, "a.content__list--item--aside").get_attribute("href")
            crawl_time = time.strftime("%Y-%m-%d %H:%M:%S")

            # æå–æˆ¿å±‹è¯¦æƒ…
            details = [d.text.strip() for d in house.find_elements(By.CSS_SELECTOR, "p.content__list--item--des *") 
                      if d.text.strip() and d.text.strip() != '/']
            house_details = details[len(area_info):] if area_info else details

            area_size = 'æ— é¢ç§¯'
            direction = 'æ— æœå‘'
            layout = 'æ— æˆ·å‹'
            floor = 'æ— æ¥¼å±‚'
            for d in house_details:
                if 'ã¡' in d:
                    area_size = d
                elif any(k in d for k in ['ä¸œ', 'å—', 'è¥¿', 'åŒ—']):
                    direction = d
                elif any(k in d for k in ['å®¤', 'å…', 'å«']):
                    layout = d
                elif 'æ¥¼å±‚' in d:
                    floor = d

            # ä¿å­˜åˆ°CSV
            with open(CSV_FILE, mode='a', encoding='utf-8', newline='') as f:
                writer = csv.DictWriter(f, fieldnames=[
                    'é¡µç ', 'æ ‡é¢˜', 'ä»·æ ¼', 'åŒºåŸŸ', 'æˆ¿å­é¢ç§¯', 'æœå‘', 'æˆ¿å±‹ç±»å‹', 'æ¥¼å±‚', 'é“¾æ¥', 'çˆ¬å–æ—¶é—´'
                ])
                writer.writerow({
                    'é¡µç ': page,
                    'æ ‡é¢˜': title,
                    'ä»·æ ¼': price,
                    'åŒºåŸŸ': area,
                    'æˆ¿å­é¢ç§¯': area_size,
                    'æœå‘': direction,
                    'æˆ¿å±‹ç±»å‹': layout,
                    'æ¥¼å±‚': floor,
                    'é“¾æ¥': link,
                    'çˆ¬å–æ—¶é—´': crawl_time
                })
            print(f"ğŸ“„  ä¿å­˜ï¼š{title} | {price}")

        time.sleep(random.uniform(2, 4))  # çˆ¬å–åå»¶è¿Ÿï¼Œé™ä½åçˆ¬

    except Exception as e:
        print(f"âŒ  é¡µç {page}è§£æé”™è¯¯ï¼š{str(e)}")

# -------------------------- æ‰§è¡Œçˆ¬å– --------------------------
if __name__ == "__main__":
    try:
        print(f"ğŸš€  å¼€å§‹çˆ¬å–ä¸´æ¸¯1-{PAGE_END}é¡µ")
        for page in range(PAGE_START, PAGE_END + 1):
            crawl_page(page)
        print(f"ğŸ‰  çˆ¬å–å®Œæˆï¼blockedé¡µç ï¼š{BLOCKED_PAGES}")
    finally:
        driver.quit()  # å…³é—­æµè§ˆå™¨